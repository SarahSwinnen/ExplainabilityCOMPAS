{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01e5cd2",
   "metadata": {},
   "source": [
    "# Explainable AI: COMPAS Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a5fcb",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ce64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fecde",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change file name for data if using different version\n",
    "dfOriginal = pd.read_csv(\"cox-violent-parsed_filt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4907ef",
   "metadata": {},
   "source": [
    "Remove duplicates, only one row per name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a40607",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProcessed = dfOriginal.drop_duplicates(subset=['name'])\n",
    "dfProcessed.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6410cf",
   "metadata": {},
   "source": [
    "Remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a70cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProcessed = dfProcessed[['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', 'is_recid']]\n",
    "dfProcessed.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed6b3f",
   "metadata": {},
   "source": [
    "Remove -1 is_recid (must be binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cdd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we expect to be dropped\n",
    "# Just using this to double check\n",
    "dfCheck = dfProcessed.loc[dfProcessed['is_recid'] < 0]\n",
    "dfCheck.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ce462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the invalid is_recid values\n",
    "dfProcessed = dfProcessed.loc[dfProcessed['is_recid'] > -1]\n",
    "dfProcessed.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc508f65",
   "metadata": {},
   "source": [
    "Missing value strategy\n",
    "1. Numerical values --> MEDIAN imputation\n",
    "2. Categorical values --> MODE imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Any NaN values?\\n\", dfProcessed.isnull().values.any())\n",
    "# ^^ To check if any NaNs\n",
    "# put it bc I tried a heatmap and it looked empty so double checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d67996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "numCols = ['age', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count']\n",
    "numImputer = SimpleImputer(strategy = 'median')\n",
    "dfProcessed[numCols] = numImputer.fit_transform(dfProcessed[numCols])\n",
    "\n",
    "# Categorical columns\n",
    "catCols = ['sex', 'race', 'c_charge_degree']\n",
    "catImputer = SimpleImputer(strategy = 'most_frequent') # most_frequent = mode\n",
    "dfProcessed[catCols] = catImputer.fit_transform(dfProcessed[catCols])\n",
    "\n",
    "print(\"Any NaN values?\\n\", dfProcessed.isnull().values.any())\n",
    "# no more NaNs :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70fc1e",
   "metadata": {},
   "source": [
    "Smote? Impute from other dataset? Impute from same dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should discuss what the plan is for this part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb260cb8",
   "metadata": {},
   "source": [
    "Dummy Model\n",
    "(idk how to approach this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13219e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure how to approach the dummy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac9818",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dfProcessed['is_recid'] # x-axis\n",
    "features = dfProcessed.drop('is_recid', axis = 1) # y-axis\n",
    "\n",
    "testSize = 0.3 # change this variable if you want different train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(target, features, test_size=testSize, random_state=44)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
